{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скрипт предназначен для извлечения причины запрета лекарства из приказа о ее запрете.\n",
    "\n",
    "Мы хотим построить алгоритм отделяющий \"общие слова\" от настоящей причины о запрете. \n",
    "\n",
    "Для некоторых лекарственных средств, мы знаем причины из ручной разметки, и в основном она  описана одним предложением.\n",
    "Для обучения алгоритма машинного обучения кроме положительных примеров хотелось бы иметь и отрицательные.\n",
    "В то же время текст приказа довольно объемный, поэтому случайно взятое предложение из приказа почти наверное будет \"не причиной\" о запрете, это дает нам право восполнить выборку отрицательными примерами.\n",
    "\n",
    "После обучения алгоритма, на этапе предсказания он применяется к каждому из предложений приказа, и выбирается предложение с наибольшей вероятностью нахождения в нем причины о запрете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# считаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('./med_df_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_excel('./Report_Database.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# предобработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тут мы разбиваем тексты из приказа на предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# разиваем текст на предложения\n",
    "a['preprocessed_order'] = a['Приказ'].fillna('').apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция которая сделает каждое предложение из текста объектом\n",
    "def unlistify(df, column):\n",
    "    matches = [i for i,n in enumerate(df.columns)\n",
    "             if n==column]\n",
    "\n",
    "    if len(matches)==0:\n",
    "        raise Exception('Failed to find column named ' + column +'!')\n",
    "    if len(matches)>1:\n",
    "        raise Exception('More than one column named ' + column +'!')\n",
    "\n",
    "    col_idx = matches[0]\n",
    "\n",
    "      # Helper function to expand and repeat the column col_idx\n",
    "    def fnc(d): \n",
    "        row = list(d.values[0])\n",
    "        bef = row[:col_idx]\n",
    "        aft = row[col_idx+1:]\n",
    "        col = row[col_idx]\n",
    "        z = [bef + [c] + aft for c in col]\n",
    "        return pd.DataFrame(z)\n",
    "\n",
    "    col_idx += len(df.index.shape) # Since we will push reset the index\n",
    "    index_names = list(df.index.names)\n",
    "    column_names = list(index_names) + list(df.columns)\n",
    "    return (df\n",
    "          .reset_index()\n",
    "          .groupby(level=0,as_index=0)\n",
    "          .apply(fnc)\n",
    "          .rename(columns = lambda i :column_names[i])\n",
    "          .set_index(index_names)\n",
    "          )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = unlistify(a, 'preprocessed_order').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = a[['index','preprocessed_order']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = b.reset_index()[['index','Причины забраковки']].rename(columns={'Причины забраковки':'preprocessed_order'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['target'] = 0\n",
    "train_set['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([train_set, test_set]).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = pymystem3.Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full['stemmed_order'] = full['preprocessed_order'].apply(lambda x: ''.join(stemmer.lemmatize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kolya/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "full_tfidf = vect.fit_transform(full['stemmed_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# lgb.LG.fit(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier().fit(full_tfidf, full['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = clf.predict_proba(full_tfidf[train_set.shape[0]:])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68533, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['pred'] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# проверим как это сработало, на случайных лекарствах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = get_random() # выберем случайные приказы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_check = test_set[test_set['index'].isin(indexes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kolya/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "quality_check['max_pred'] = quality_check.groupby('index').pred.transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answers = quality_check[quality_check['pred'] == quality_check['max_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Натрия дисульфит», «Количественное определение.\n",
      "Видимые частицы», «Количественное определение.\n",
      "Климовой» (Россия) в  связи  с  развитием  нежелательной  реакции.\n",
      "Видимые частицы» - серии 290515.2.\n",
      "Умет, Тамбовская  область), показатель  «Упаковка» (отсутствует  вторичная  упаковка) — серии  031115.\n"
     ]
    }
   ],
   "source": [
    "for i in answers.iterrows():\n",
    "    print(i[1].preprocessed_order)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
